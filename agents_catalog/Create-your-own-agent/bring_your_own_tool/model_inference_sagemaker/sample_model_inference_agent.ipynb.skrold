{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24cee39a-a77d-4493-a532-56935aa07fd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sample Model Inference Agent Walkthrough\n",
    "\n",
    "This notebook will walk users through setting up a Model Inference Agent that leverages  SageMaker Jumpstart models\n",
    "\n",
    "This agent utilizes Amazon SageMaker  to deploy the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f4dea3-0547-4802-975a-8ba202e82b39",
   "metadata": {},
   "source": [
    "# Pre-requisites\n",
    "\n",
    "1. Go through the notebook environment setup in the agents_catalog/0-Notebook-environment/ folder\n",
    "\n",
    "2. Modify and Deploy jumpstart_model.yaml to your AWS account to instantiate a SageMaker endpoint and a lambda function that invokes the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c401dd7-dd66-44cd-a02a-fcdd95d98605",
   "metadata": {},
   "source": [
    "#### Ensure the latest version of boto3 is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73745fd0-9df8-4f95-b58e-843c958840ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3 @ file:///home/conda/feedstock_root/build_artifacts/boto3_1739930060723/work\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0740af25-3bfb-4394-a68e-6d5e342fccbe",
   "metadata": {},
   "source": [
    "#### Load in environment variables to notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b5a72d5-8584-4b55-9d62-04feff651ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve import path\n",
    "%store -r IMPORTS_PATH\n",
    "\n",
    "# Retrieve account info\n",
    "%store -r account_id\n",
    "%store -r region\n",
    "\n",
    "# Retrieve model lists\n",
    "%store -r agent_foundation_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef228e7-54c0-4925-8c06-6d172ab3286c",
   "metadata": {},
   "source": [
    "#### Retrieve imports environment variable and bring libraries into notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae4b0cf3-76bf-4287-9b40-cc14566ebf8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "Successfully imported necessary libraries into notebook\n"
     ]
    }
   ],
   "source": [
    "%run $IMPORTS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96053d0a-6dfd-4623-aea4-d7eaedc6dc63",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Agent Creation\n",
    "In this section we create the sub-agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e974c4f-200d-499a-ba94-70de02a88486",
   "metadata": {},
   "source": [
    "#### Define agent configuration below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11e88b67-5f84-45be-90af-673c11730230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_name = 'Model-inference-expert'\n",
    "agent_description = \"Foundation model inference with SageMaker Jumpstart\"\n",
    "agent_instruction = \"\"\"You are a machine learning expert at deploying and running inference with Amazon SageMaker Jumpstart models. Your primary task is to run model inference and provide relevant insights. Use only the appropriate tools as required by the specific question. \n",
    "When providing your response: a. Start with a brief summary of your understanding of the user's query. \n",
    "b. Explain the steps you're taking to address the query. Ask for clarifications from the user if required. \n",
    "c. Present the results of the model inference.\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2b94bc-1ed8-4542-9315-1494d76d4445",
   "metadata": {},
   "source": [
    "#### Instantiate agent with the desired configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37eb6515-56ec-4bf5-afc1-99f303add381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BLNRH1JISF',\n",
       " 'TSTALIASID',\n",
       " 'arn:aws:bedrock:ap-northeast-1 :942514891246:agent-alias/BLNRH1JISF/TSTALIASID')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents = AgentsForAmazonBedrock()\n",
    "\n",
    "model_inference_agent = agents.create_agent(\n",
    "    agent_name,\n",
    "    agent_description,\n",
    "    agent_instruction,\n",
    "    agent_foundation_model,\n",
    "    code_interpretation=False,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "model_inference_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fe77f5-6e24-4bab-a192-480091e5bd09",
   "metadata": {},
   "source": [
    "#### Extract useful agent information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1db8b112-ddc8-4a57-817a-528a20a72880",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BLNRH1JISF', 'arn:aws:bedrock:ap-northeast-1 :942514891246:agent/BLNRH1JISF')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inference_agent_id = model_inference_agent[0]\n",
    "model_inference_agent_arn = f\"arn:aws:bedrock:{region}:{account_id}:agent/{model_inference_agent_id}\"\n",
    "\n",
    "model_inference_agent_id, model_inference_agent_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e922d7b4-bbef-4462-bdfd-c40b8cbf2e9d",
   "metadata": {},
   "source": [
    "#### Define function details for ActionGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "491d747d-42a5-4ccd-a535-d8d10f60132b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function_defs = [\n",
    "    {\n",
    "      \"name\": \"invoke_model_inference\",\n",
    "      \"description\": \"Run inference with the deployed model\",\n",
    "      \"parameters\": {\n",
    "        \"input_text\": {\n",
    "          \"description\": \"input text to be sent to the model\",\n",
    "          \"required\": True,\n",
    "          \"type\": \"string\"\n",
    "        }\n",
    "      },\n",
    "      \"requireConfirmation\": \"DISABLED\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7679e8d0-b9f8-48f4-87c1-dc7976a2ded4",
   "metadata": {},
   "source": [
    "#### Attach Lambda function and create ActionGroup\n",
    "Note: This uses the default Lambda function name \"imaging-biomarker-lambda\", this could be different in your account so double-check that this function exists and if not change the lambda_function_name in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40e64c59-8ed0-461f-a595-5bc2996a8166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'model_inference_lambda_function_arn' (str)\n"
     ]
    }
   ],
   "source": [
    "# Define Lambda func. details, hardcode Lambda function name\n",
    "model_inference_lambda_function_name = \"foundation-model-invoke\"  # Change if different in your account\n",
    "model_inference_lambda_function_arn = f\"arn:aws:lambda:{region}:{account_id}:function:{model_inference_lambda_function_name}\"\n",
    "%store model_inference_lambda_function_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43f432af-cacd-4db7-bb4d-d2d2f0566644",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating action group: Model-inference...\n",
      "Lambda ARN: arn:aws:lambda:ap-northeast-1 :942514891246:function:foundation-model-invoke\n",
      "Agent functions: [{'name': 'invoke_model_inference', 'description': 'Run inference with the deployed model', 'parameters': {'input_text': {'description': 'input text to be sent to the model', 'required': True, 'type': 'string'}}, 'requireConfirmation': 'DISABLED'}]\n"
     ]
    }
   ],
   "source": [
    "agents.add_action_group_with_lambda(\n",
    "    agent_name=agent_name,\n",
    "    lambda_function_name=model_inference_lambda_function_name,\n",
    "    source_code_file=model_inference_lambda_function_arn,\n",
    "    agent_action_group_name=\"Model-inference\",\n",
    "    agent_action_group_description=\"Actions for running inference with specialized model\",\n",
    "    agent_functions=function_defs,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8799ab-77a8-4431-8edd-d1c1a7015c7c",
   "metadata": {},
   "source": [
    "#### Add resource based policy to Lambda function to allow agent to invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f12947d7-2652-4664-b4e2-1712d4baf366",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource policy added successfully.\n",
      "Response: {'ResponseMetadata': {'RequestId': '6a769d24-f058-4706-a7fa-cf4bdfcaf312', 'HTTPStatusCode': 201, 'HTTPHeaders': {'date': 'Tue, 25 Mar 2025 17:35:35 GMT', 'content-type': 'application/json', 'content-length': '369', 'connection': 'keep-alive', 'x-amzn-requestid': '6a769d24-f058-4706-a7fa-cf4bdfcaf312'}, 'RetryAttempts': 0}, 'Statement': '{\"Sid\":\"AllowModelInferenceAgentAccess2\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"bedrock.amazonaws.com\"},\"Action\":\"lambda:InvokeFunction\",\"Resource\":\"arn:aws:lambda:ap-northeast-1 :942514891246:function:foundation-model-invoke\",\"Condition\":{\"ArnLike\":{\"AWS:SourceArn\":\"arn:aws:bedrock:ap-northeast-1 :942514891246:agent/BLNRH1JISF\"}}}'}\n"
     ]
    }
   ],
   "source": [
    "lambda_client = boto3.client('lambda', region)\n",
    "\n",
    "# Define the resource policy statement\n",
    "policy_statement = {\n",
    "    \"Sid\": \"AllowBedrockAgentAccess\",\n",
    "    \"Effect\": \"Allow\",\n",
    "    \"Principal\": {\n",
    "        \"Service\": \"bedrock.amazonaws.com\"\n",
    "    },\n",
    "    \"Action\": \"lambda:InvokeFunction\",\n",
    "    \"Resource\": model_inference_lambda_function_arn,\n",
    "    \"Condition\": {\n",
    "        \"ArnEquals\": {\n",
    "            \"aws:SourceArn\": model_inference_agent_arn\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Get the current policy\n",
    "    response = lambda_client.get_policy(FunctionName=model_inference_lambda_function_arn)\n",
    "    current_policy = json.loads(response['Policy'])\n",
    "    \n",
    "    # Add the new statement to the existing policy\n",
    "    current_policy['Statement'].append(policy_statement)\n",
    "    \n",
    "except lambda_client.exceptions.ResourceNotFoundException:\n",
    "    # If there's no existing policy, create a new one\n",
    "    current_policy = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [policy_statement]\n",
    "    }\n",
    "\n",
    "# Convert the policy to JSON string\n",
    "updated_policy = json.dumps(current_policy)\n",
    "\n",
    "# Add or update the resource policy\n",
    "response = lambda_client.add_permission(\n",
    "    FunctionName=model_inference_lambda_function_arn,\n",
    "    StatementId=\"AllowModelInferenceAgentAccess2\",\n",
    "    Action=\"lambda:InvokeFunction\",\n",
    "    Principal=\"bedrock.amazonaws.com\",\n",
    "    SourceArn=model_inference_agent_arn\n",
    ")\n",
    "\n",
    "print(\"Resource policy added successfully.\")\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7918a1b7-9dbe-4345-a1a7-870d962bce17",
   "metadata": {},
   "source": [
    "#### Invoke Model Inference Expert Agent Test Alias to see that it answers question properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f1dbd7b-b9c2-427b-b7e5-23961e64d877",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request sent to Agent:\n",
      "{'ResponseMetadata': {'RequestId': 'c67e25e9-103f-453a-807c-e540514c580c', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 25 Mar 2025 22:48:17 GMT', 'content-type': 'application/vnd.amazon.eventstream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'x-amzn-requestid': 'c67e25e9-103f-453a-807c-e540514c580c', 'x-amz-bedrock-agent-session-id': '3de7f6ae-09cb-11f0-b8ae-8a4ca2a7c47b', 'x-amzn-bedrock-agent-content-type': 'application/json'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'sessionId': '3de7f6ae-09cb-11f0-b8ae-8a4ca2a7c47b', 'completion': <botocore.eventstream.EventStream object at 0x7f3e7a9a4310>}\n",
      "====================\n",
      "Agent processing query now\n",
      "====================\n",
      "Agent Answer: A fox is chasing the dog.\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "bedrock_agent_runtime_client = boto3.client(\"bedrock-agent-runtime\", region)\n",
    "\n",
    "session_id = str(uuid.uuid1())\n",
    "\n",
    "\n",
    "test_query = \"Summarize this text: The quick brown fox jumps over the lazy dog near the river on a sunny day while birds chirp in the trees above.\"\n",
    "\n",
    "response = bedrock_agent_runtime_client.invoke_agent(\n",
    "      inputText=test_query,\n",
    "      agentId=model_inference_agent_id,\n",
    "      agentAliasId=\"TSTALIASID\", \n",
    "      sessionId=session_id,\n",
    "      enableTrace=True, \n",
    "      endSession=False,\n",
    "      sessionState={}\n",
    ")\n",
    "\n",
    "print(\"Request sent to Agent:\\n{}\".format(response))\n",
    "print(\"====================\")\n",
    "print(\"Agent processing query now\")\n",
    "print(\"====================\")\n",
    "\n",
    "# Initialize an empty string to store the answer\n",
    "answer = \"\"\n",
    "\n",
    "# Iterate through the event stream\n",
    "for event in response['completion']:\n",
    "    # Check if the event is a 'chunk' event\n",
    "    if 'chunk' in event:\n",
    "        chunk_obj = event['chunk']\n",
    "        if 'bytes' in chunk_obj:\n",
    "            # Decode the bytes and append to the answer\n",
    "            chunk_data = chunk_obj['bytes'].decode('utf-8')\n",
    "            answer += chunk_data\n",
    "\n",
    "# Now 'answer' contains the full response from the agent\n",
    "print(\"Agent Answer: {}\".format(answer))\n",
    "print(\"====================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3cb851-c2f5-4883-9a9b-151cbd35daef",
   "metadata": {},
   "source": [
    "#### Now that agent has been tested via direct invoke, prepare it by creating an alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c953ca-b104-4604-9971-bc89c3b1f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inference_agent_alias_id, model_inference_agent_alias_arn = agents.create_agent_alias(\n",
    "    model_inference_agent[0], 'v1'\n",
    ")\n",
    "\n",
    "%store model_inference_agent_alias_arn\n",
    "model_inference_agent_alias_id, model_inference_agent_alias_arn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
